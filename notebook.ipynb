{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu.model import Interpreter\n",
    "from rasa_nlu.test import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasaLangClassifier:\n",
    "    \n",
    "    \n",
    "    def __init__(self, config_str, base_dir=None, verbose=0):\n",
    "        self.verbose = verbose\n",
    "        self.base_dir = base_dir\n",
    "        self.data_dir = os.path.join(self.base_dir, 'data')\n",
    "        self.models_dir = os.path.join(self.base_dir, 'models')\n",
    "        self.project_name = 'current'\n",
    "        self.model_name = 'nlu'\n",
    "        self.last_model_dir = os.path.join(self.models_dir, self.project_name, self.model_name)\n",
    "        self.log_file = os.path.join(self.base_dir, 'nlu_model.log')\n",
    "        self.nlu_file = os.path.join(self.data_dir, 'nlu.md')\n",
    "        self.config_file = os.path.join(self.base_dir, 'config.yml')\n",
    "        \n",
    "        logging.basicConfig(filename=self.log_file, level=logging.INFO)\n",
    "\n",
    "        if os.path.exists(self.base_dir):\n",
    "            shutil.rmtree(self.base_dir)\n",
    "        for d in [self.data_dir, self.last_model_dir]:\n",
    "            os.makedirs(d)\n",
    "        if self.verbose > 0:\n",
    "            print(\"Successfully created base directory structure {}\".format(base_dir))\n",
    "\n",
    "        # write configuration to config file\n",
    "        with open(self.config_file, \"w\") as text_file:\n",
    "            print(config_str, file=text_file)\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # format data into Rasa NLU markdown file format\n",
    "        df_data = pd.DataFrame({'text': X})\n",
    "        df_data['intent'] = y.apply(\n",
    "            lambda i: '+'.join(i.index[i>0]), axis=1\n",
    "        )\n",
    "        series_intents = df_data.groupby('intent')['text'].apply(\n",
    "            lambda texts: '## intent:' + texts.name + '\\n' + '\\n'.join(['- ' + t for t in texts])\n",
    "        )\n",
    "        intents = '\\n\\n'.join(series_intents)\n",
    "        with open(self.nlu_file, \"w\") as text_file:\n",
    "            print(intents, file=text_file)\n",
    "        self.tags = df_data['intent'].unique()\n",
    "        \n",
    "        training_data = load_data(self.nlu_file)\n",
    "        trainer = Trainer(config.load(self.config_file))\n",
    "        trainer.train(training_data)\n",
    "        model_directory = trainer.persist(\n",
    "            self.models_dir, \n",
    "            project_name=self.project_name, \n",
    "            fixed_model_name=self.model_name\n",
    "        )\n",
    "\n",
    "        self.interpreter = Interpreter.load(self.last_model_dir)\n",
    "    \n",
    "    def predict_conf(self, X):\n",
    "        def predict_conf_single(self, question):\n",
    "            # get confidence from interpreter\n",
    "            try:\n",
    "                intent_ranking = self.interpreter.parse(question)['intent_ranking']\n",
    "            except AttributeError as error:\n",
    "                raise AttributeError('The model needs to be trained first.') from error\n",
    "            out = pd.Series(0, index=self.tags)            \n",
    "            df_intents = pd.DataFrame.from_dict(intent_ranking)\n",
    "            out[df_intents['name']] = df_intents['confidence']\n",
    "            # return a pd.Series()\n",
    "            return(out)\n",
    "        \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        out = pd.DataFrame([predict_conf_single(self, Xi) for Xi in X_])\n",
    "        return(out)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        def predict_single(self, question):\n",
    "            s_conf = self.predict_conf(question)\n",
    "            indiv_tags = list(set([\n",
    "                item \n",
    "                for sublist in [t.split('+') for t in self.tags] \n",
    "                for item in sublist\n",
    "            ]))\n",
    "            s = pd.Series(0.0, index=indiv_tags)\n",
    "            s[s_conf.iloc[0].idxmax().split('+')] = 1\n",
    "            return(s)\n",
    "    \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        return(pd.DataFrame([predict_single(self, Xi) for Xi in X_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasaClassifier:\n",
    "    \n",
    "    \n",
    "    def __init__(self, config_str, base_dir=None, verbose=0):\n",
    "        self.config_str = config_str\n",
    "        self.base_dir = base_dir # TODO replace by temp folder\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        self.langs = [lang.replace('lang:', '') for lang in y.filter(regex='^lang:').columns]\n",
    "        self.lang_dirs = {lang: os.path.join(self.base_dir, lang) for lang in self.langs}\n",
    "        self.lang_classifiers = {}\n",
    "        for lang in self.langs:\n",
    "            self.lang_classifiers[lang] = RasaLangClassifier(\n",
    "                self.config_str.format(lang=lang),\n",
    "                self.lang_dirs[lang],\n",
    "                verbose=self.verbose\n",
    "            )\n",
    "        for lang, cls in self.lang_classifiers.items():\n",
    "            cls.train(\n",
    "                X[y['lang:' + lang] > 0],\n",
    "                y[y['lang:' + lang] > 0].filter(regex='^[^lang:]')\n",
    "            )\n",
    "        \n",
    "    def _internal_predict(self, X, func_name, **kwargs):\n",
    "        def check_langs(det_lang):\n",
    "            unknown_langs = list(set(det_lang).difference(set(self.langs)))\n",
    "            if len(unknown_langs) > 0:\n",
    "                raise IndexError(\n",
    "                    'Unsupported languages detected: {unk}. Available: {langs}.'.format(\n",
    "                        unk=unknown_langs, langs=self.langs\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        \n",
    "        # NOTE this would be part of the prediction package in final implementation\n",
    "        try:\n",
    "            lang_model = fasttext.load_model('lid.176.ftz')\n",
    "        except:\n",
    "            wget.download('https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz')\n",
    "            lang_model = fasttext.load_model('lid.176.ftz')\n",
    "        det_lang = np.array([lang_model.predict(q)[0][0].replace('__label__','') for q in X_])\n",
    "        check_langs(det_lang)\n",
    "        out = pd.DataFrame()\n",
    "        ids = []\n",
    "        for lang in np.sort(list(set(det_lang))):\n",
    "            func = getattr(cls.lang_classifiers[lang], func_name)\n",
    "            out_l = func(np.array(X_)[det_lang==lang], **kwargs)\n",
    "            ids = np.concatenate([ids, np.where(det_lang==lang)[0]])\n",
    "            out = out.append(out_l, ignore_index=True)\n",
    "        lang_dummies = pd.get_dummies(pd.Series(['lang:' + lang for lang in np.sort(det_lang)]))\n",
    "        out = pd.concat([lang_dummies, out], axis=1).iloc[np.argsort(ids)]\n",
    "        return(out)\n",
    "    \n",
    "    def predict_conf(self, X):\n",
    "        return(self._internal_predict(X, 'predict_conf', **{}))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return(self._internal_predict(X, 'predict', **{}))\n",
    "\n",
    "    def score(self, X, y, func, **kwargs):\n",
    "        y_hat = self._internal_predict(X, 'predict', **{})\n",
    "        s = func(\n",
    "            np.array(y, dtype='float'), \n",
    "            np.array(y_hat[y.columns], dtype='float'), \n",
    "            **kwargs\n",
    "        )\n",
    "        return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_str = '''\n",
    "language: {lang}\n",
    "\n",
    "pipeline:\n",
    "- name: \"WhitespaceTokenizer\"\n",
    "- name: \"RegexFeaturizer\"\n",
    "- name: \"CRFEntityExtractor\"\n",
    "- name: \"EntitySynonymMapper\"\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "  analyzer: \"char_wb\"\n",
    "  min_ngram: 1\n",
    "  max_ngram: 6\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "  analyzer: \"word\"\n",
    "  min_ngram: 1\n",
    "  max_ngram: 3\n",
    "- name: \"EmbeddingIntentClassifier\"\n",
    "  intent_tokenization_flag: true\n",
    "  intent_split_symbol: \"+\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.read_csv('co_sh_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Xy['Question'], Xy.drop('Question', axis=1), test_size=0.2, random_state=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.conda/envs/bryter_test/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'co:ltd+co:plc+sh' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "Epochs: 100%|██████████| 300/300 [00:13<00:00, 21.81it/s, loss=0.330, acc=1.000]\n",
      "/home/david/.conda/envs/bryter_test/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'co:ltd+co:plc+sh' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "Epochs: 100%|██████████| 300/300 [00:12<00:00, 27.91it/s, loss=0.211, acc=1.000]\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "cls = RasaClassifier(config_str, './rasa_full/')\n",
    "\n",
    "cls.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.score(\n",
    "    X_test, \n",
    "    y_test, \n",
    "    sklearn.metrics.recall_score, \n",
    "    average='samples'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>lang:de</th>\n",
       "      <th>lang:en</th>\n",
       "      <th></th>\n",
       "      <th>co:ltd</th>\n",
       "      <th>sh</th>\n",
       "      <th>co:plc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How many shareholders does a public company have?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I give shares to my son?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some examples of private limited comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At what age can you own shares?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wie hoch ist das Stammkapital einer GmbH?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  lang:de  lang:en       \\\n",
       "0  How many shareholders does a public company have?        0        1  0.0   \n",
       "1                       Can I give shares to my son?        0        1  0.0   \n",
       "2  What are some examples of private limited comp...        0        1  0.0   \n",
       "3                    At what age can you own shares?        0        1  0.0   \n",
       "4          Wie hoch ist das Stammkapital einer GmbH?        1        0  0.0   \n",
       "\n",
       "   co:ltd   sh  co:plc  \n",
       "0     0.0  0.0     1.0  \n",
       "1     0.0  1.0     0.0  \n",
       "2     1.0  0.0     0.0  \n",
       "3     0.0  1.0     0.0  \n",
       "4     0.0  1.0     0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        X_test.reset_index()['Question'], \n",
    "        cls.predict(X_test).reset_index().drop('index', axis=1)\n",
    "    ], \n",
    "    axis=1\n",
    ").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bryter_test",
   "language": "python",
   "name": "bryter_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
