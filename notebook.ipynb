{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pprint\n",
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu import config\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu.model import Interpreter\n",
    "from rasa_nlu.test import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This format avoids some text appearing twice, linked to either the same or other intent.\n",
    "data_en = {\n",
    "    'private company': 'co:ltd',\n",
    "    'limited company': 'co:ltd',\n",
    "    'private limited company': 'co:ltd',\n",
    "    'limited liability company': 'co:ltd',\n",
    "    \n",
    "    'publicly traded company': 'co:plc',\n",
    "    'public company': 'co:plc',\n",
    "    'public limited company': 'co:plc',\n",
    "    \n",
    "    'shareholder': 'sh',\n",
    "    'stockholder': 'sh',\n",
    "    \n",
    "    'shareholder of a limited company': 'sh+co:ltd',\n",
    "    'shareholder of a public company': 'sh+co:plc'\n",
    "}\n",
    "data_de = {\n",
    "    'gmbh': 'co:ltd',\n",
    "    'beschränkter haftung': 'co:ltd',\n",
    "    \n",
    "    'plc': 'co:plc',\n",
    "    'ag': 'co:plc',\n",
    "    'aktiengesellschaft': 'co:plc',\n",
    "    \n",
    "    'mehrheitseigner': 'sh',\n",
    "}\n",
    "data = {'en': data_en, 'de': data_de}\n",
    "\n",
    "config_str = '''\n",
    "language: {lang}\n",
    "\n",
    "pipeline:\n",
    "- name: \"WhitespaceTokenizer\"\n",
    "- name: \"RegexFeaturizer\"\n",
    "- name: \"CRFEntityExtractor\"\n",
    "- name: \"EntitySynonymMapper\"\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "  analyzer: \"char_wb\"\n",
    "  min_ngram: 1\n",
    "  max_ngram: 6\n",
    "- name: \"CountVectorsFeaturizer\"\n",
    "  analyzer: \"word\"\n",
    "  min_ngram: 1\n",
    "  max_ngram: 3\n",
    "- name: \"EmbeddingIntentClassifier\"\n",
    "  intent_tokenization_flag: true\n",
    "  intent_split_symbol: \"+\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasaLangClassifier:\n",
    "    \n",
    "    \n",
    "    def __init__(self, base_dir, data, config_str, overwrite=False, tags=None, verbose=0):\n",
    "        self.verbose = verbose\n",
    "        self.base_dir = base_dir\n",
    "        self.data_dir = os.path.join(self.base_dir, 'data')\n",
    "        self.models_dir = os.path.join(self.base_dir, 'models')\n",
    "        self.project_name = 'current'\n",
    "        self.model_name = 'nlu'\n",
    "        self.last_model_dir = os.path.join(self.models_dir, self.project_name, self.model_name)\n",
    "        self.log_file = os.path.join(self.base_dir, 'nlu_model.log')\n",
    "        self.nlu_file = os.path.join(self.data_dir, 'nlu.md')\n",
    "        self.config_file = os.path.join(self.base_dir, 'config.yml')\n",
    "        self.tags = tags\n",
    "        \n",
    "        logging.basicConfig(filename=self.log_file, level=logging.INFO)\n",
    "\n",
    "        # check if a model already exists and pre-delete if overwrite flag active\n",
    "        if os.path.exists(self.base_dir):\n",
    "            if not overwrite:\n",
    "                raise(OSError('Base directory for classifier already exists.'))\n",
    "            else:\n",
    "                shutil.rmtree(self.base_dir)\n",
    "        for d in [self.data_dir, self.last_model_dir]:\n",
    "            os.makedirs(d)\n",
    "        if self.verbose > 0:\n",
    "            print(\"Successfully created base directory structure {}\".format(base_dir))\n",
    "\n",
    "        # format data dict into Rasa NLU markdown file format\n",
    "        df_data = pd.DataFrame.from_dict(list(data.items()))\n",
    "        df_data.columns = ['text', 'intent']\n",
    "        i = df_data['intent'].unique()[0]\n",
    "        series_intents = df_data.groupby('intent')['text'].apply(\n",
    "            lambda texts: '## intent:' + texts.name + '\\n' + '\\n'.join(['- ' + t for t in texts])\n",
    "        )\n",
    "        intents = '\\n\\n'.join(series_intents)\n",
    "        with open(self.nlu_file, \"w\") as text_file:\n",
    "            print(intents, file=text_file)\n",
    "\n",
    "        # write configuration to config file\n",
    "        with open(self.config_file, \"w\") as text_file:\n",
    "            print(config_str, file=text_file)\n",
    "\n",
    "    def train(self):\n",
    "        training_data = load_data(self.nlu_file)\n",
    "        trainer = Trainer(config.load(self.config_file))\n",
    "        trainer.train(training_data)\n",
    "        model_directory = trainer.persist(\n",
    "            self.models_dir, \n",
    "            project_name=self.project_name, \n",
    "            fixed_model_name=self.model_name\n",
    "        )\n",
    "        self.interpreter = Interpreter.load(self.last_model_dir)\n",
    "    \n",
    "    def predict_conf(self, X):\n",
    "        def predict_conf_single(self, question):\n",
    "            # get confidence from interpreter\n",
    "            try:\n",
    "                intent_ranking = self.interpreter.parse(question)['intent_ranking']\n",
    "            except AttributeError as error:\n",
    "                raise AttributeError('The model needs to be trained first.') from error\n",
    "            if self.tags is None:\n",
    "                self.tags = [i['name'] for i in intent_ranking]\n",
    "            out = pd.Series(0, index=self.tags)            \n",
    "            df_intents = pd.DataFrame.from_dict(intent_ranking)\n",
    "            out[df_intents['name']] = df_intents['confidence']\n",
    "            # return a pd.Series()\n",
    "            return(out)\n",
    "        \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        out = pd.DataFrame([predict_conf_single(self, Xi) for Xi in X_])\n",
    "        return(out)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        def predict_single(self, question):\n",
    "            s_conf = self.predict_conf(question)\n",
    "            indiv_tags = list(set([\n",
    "                item \n",
    "                for sublist in [t.split('+') for t in self.tags] \n",
    "                for item in sublist\n",
    "            ]))\n",
    "            s = pd.Series(0.0, index=indiv_tags)\n",
    "            s[s_conf.iloc[0].idxmax().split('+')] = 1\n",
    "            return(s)\n",
    "    \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        return(pd.DataFrame([predict_single(self, Xi) for Xi in X_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasaClassifier:\n",
    "    \n",
    "    \n",
    "    def __init__(self, base_dir, data, config_str, langs, overwrite=False, verbose=0):\n",
    "        self.verbose = verbose\n",
    "        self.tags = list(set([\n",
    "            item \n",
    "            for sublist in [d.values() for d in data.values()] \n",
    "            for item in sublist\n",
    "        ]))\n",
    "        self.base_dir = base_dir\n",
    "        self.langs = langs\n",
    "        self.lang_dirs = {lang: os.path.join(self.base_dir, lang) for lang in self.langs}\n",
    "        self.lang_classifiers = {}\n",
    "        for lang in self.langs:\n",
    "            self.lang_classifiers[lang] = RasaLangClassifier(\n",
    "                self.lang_dirs[lang], \n",
    "                data[lang], \n",
    "                config_str.format(lang=lang), \n",
    "                overwrite=overwrite,\n",
    "                tags=self.tags,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        \n",
    "    def train(self):\n",
    "        for cls in self.lang_classifiers.values():\n",
    "            cls.train()\n",
    "        \n",
    "    def _internal_predict(self, X, func_name, **kwargs):\n",
    "        def check_langs(det_lang):\n",
    "            unknown_langs = list(set(det_lang).difference(set(self.langs)))\n",
    "            if len(unknown_langs) > 0:\n",
    "                raise IndexError(\n",
    "                    'Unsupported languages detected: {unk}. Available: {langs}.'.format(\n",
    "                        unk=unknown_langs, langs=self.langs\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        X_ = [X] if np.isscalar(X) else X\n",
    "        det_lang = np.array([TextBlob(question).detect_language() for question in X_])\n",
    "        check_langs(det_lang)\n",
    "        out = pd.DataFrame()\n",
    "        ids = []\n",
    "        for lang in np.sort(list(set(det_lang))):\n",
    "            func = getattr(cls.lang_classifiers[lang], func_name)\n",
    "            out_l = func(np.array(X_)[det_lang==lang], **kwargs)\n",
    "            ids = np.concatenate([ids, np.where(det_lang==lang)[0]])\n",
    "            out = out.append(out_l, ignore_index=True)\n",
    "        lang_dummies = pd.get_dummies(pd.Series(['lang:' + lang for lang in np.sort(det_lang)]))\n",
    "        out = pd.concat([out, lang_dummies], axis=1).iloc[np.argsort(ids)]\n",
    "        return(out)\n",
    "    \n",
    "    def predict_conf(self, X):\n",
    "        return(self._internal_predict(X, 'predict_conf', **{}))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return(self._internal_predict(X, 'predict', **{}))\n",
    "    \n",
    "\n",
    "#     def score(self, X, y):\n",
    "    # TODO score() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.conda/envs/bryter_test/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'sh+co:ltd' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "/home/david/.conda/envs/bryter_test/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'sh+co:plc' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "Epochs: 100%|██████████| 300/300 [00:04<00:00, 60.60it/s, loss=0.276, acc=1.000]\n",
      "100%|██████████| 11/11 [00:00<00:00, 61.76it/s]\n",
      "/home/david/.conda/envs/bryter_test/lib/python3.6/site-packages/rasa_nlu/training_data/training_data.py:176: UserWarning: Intent 'sh' has only 1 training examples! Minimum is 2, training may fail.\n",
      "  self.MIN_EXAMPLES_PER_INTENT))\n",
      "Epochs: 100%|██████████| 300/300 [00:08<00:00, 37.05it/s, loss=0.109, acc=1.000]\n",
      "100%|██████████| 6/6 [00:00<00:00, 32.77it/s]\n"
     ]
    }
   ],
   "source": [
    "cls = RasaClassifier('./rasa_full/', data, config_str, list(data.keys()), overwrite=True)\n",
    "cls.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'Can I be shareholder of a limited company?',\n",
    "    'I want to become shareholder of a limited company.',\n",
    "    'Can I be shareholder of a limited public corporate?',\n",
    "    'Can my company be shareholder of a limited company?',\n",
    "    'Can my company be shareholder of a public corporate?',\n",
    "    'Kann ich Gesellschafter einer GmbH sein?',\n",
    "    'Wer kann Gesellschafter einer AG sein?',\n",
    "    'Kann ich mit meiner GmbH Mehrheitseigner einer AG sein?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sh</th>\n",
       "      <th>co:plc</th>\n",
       "      <th>co:ltd</th>\n",
       "      <th>lang:de</th>\n",
       "      <th>lang:en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sh  co:plc  co:ltd  lang:de  lang:en\n",
       "3  1.0     0.0     1.0        0        1\n",
       "4  1.0     0.0     1.0        0        1\n",
       "5  1.0     1.0     0.0        0        1\n",
       "6  1.0     0.0     1.0        0        1\n",
       "7  1.0     1.0     0.0        0        1\n",
       "0  0.0     1.0     0.0        1        0\n",
       "1  0.0     1.0     0.0        1        0\n",
       "2  1.0     0.0     0.0        1        0"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls.predict(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bryter_test",
   "language": "python",
   "name": "bryter_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
